{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48dc60a8-2320-435c-90e1-f7b44c170728"
      },
      "source": [
        "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac02d0d3-1136-426e-8294-0d7d9d505786"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "    \n",
        "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
        "2. <a href=\"#item32\">Download Data</a>  \n",
        "3. <a href=\"#item33\">Define Global Constants</a>  \n",
        "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
        "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
        "\n",
        "</font>\n",
        "    \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9008da8d-7cb4-4333-925d-9937c5a83ab6"
      },
      "source": [
        "## Import Libraries and Packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ff4a4c-47c2-4372-8c59-2cfda80d64e7"
      },
      "source": [
        "Let's start the lab by importing the libraries that we will be using in this lab. First we will need the library that helps us to import the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skillsnetwork"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCBkX5Mg6wMz",
        "outputId": "0fc0393f-f213-4b63-faa4-86e7c18bca5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skillsnetwork\n",
            "  Downloading skillsnetwork-0.21.9-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (7.34.0)\n",
            "Collecting ipywidgets<9,>=8 (from skillsnetwork)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5,>=4 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (4.66.4)\n",
            "Collecting comm>=0.1.3 (from ipywidgets<9,>=8->skillsnetwork)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->skillsnetwork) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.11 (from ipywidgets<9,>=8->skillsnetwork)\n",
            "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->skillsnetwork) (3.0.11)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->skillsnetwork)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2024.6.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->skillsnetwork) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->skillsnetwork) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->skillsnetwork) (0.2.13)\n",
            "Installing collected packages: widgetsnbextension, jedi, comm, ipywidgets, skillsnetwork\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.3 jedi-0.19.1 skillsnetwork-0.21.9 widgetsnbextension-4.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2cc2be08-b540-4918-b1a9-a2df287ff4d9"
      },
      "outputs": [],
      "source": [
        "import skillsnetwork\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a683d5c-10fd-4e9b-9fe7-3cd2c8928099"
      },
      "source": [
        "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "675684c0-2392-4487-953a-99b049b0450c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "683598d4-99e2-42b0-991e-00a3e5fd5d99"
      },
      "source": [
        "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "58f57fd4-ffb5-4fd7-a67c-0cf73a1cacde"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ecf765d-36f8-4262-b631-cb0f60a217d9"
      },
      "source": [
        "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f96d6994-63e4-4297-b98a-0c2ab2439cd0"
      },
      "outputs": [],
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53d76782-0cd7-4ced-8a37-096675e632d3"
      },
      "source": [
        "<a id='item32'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e55f048-ce67-455a-9e3a-dc5cc0ded766"
      },
      "source": [
        "## Download Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89eae3c7-10fc-4e55-a043-b544dd7776f4"
      },
      "source": [
        "In this section, you are going to download the data from IBM object storage using **skillsnetwork.prepare** command. skillsnetwork.prepare is a command that's used to download a zip file, unzip it and store it in a specified directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "e8a243a49aff4d7e97c9d008e4928a1e",
            "e0f46e0dc86b4db1adb3bb179598958f",
            "0d8df91aaf1f4b16b54d1675f19ea2d1",
            "000518ad4cff42b7a9ed30542d39c047",
            "a550bcafa6f246878f2ef6f28e5f7b6d",
            "8f478f75a44941f5b122db6ec0a42fa8",
            "124e5f7c9ff8437dade44bb20913da03",
            "88bfb5c1a4244fbfbd5f7c2e9b8ab9c0",
            "b1b8a4f156f64317b13b07d26701af5e",
            "de5ab5e8a035404c9f20901d054e56e2",
            "d330de7491f04f5783e94bb079a3e14a",
            "4b2371ccfc5e4b8e9c311ae4c8c88552",
            "6a6355d7d47441778e873434265f9995",
            "341d5f4d5820456d86df99e616409340",
            "c22630f0a6c64c63b491f80c753830c2",
            "7c8d039cc71241d69cbcd25f4e077a02",
            "46d3f53c5292428c81d1a05661b63593",
            "f370084ae34a43e8b77724ceb902c580",
            "02dd2b8688df49569dde27f64a96b89d",
            "d43da503d3b14bacb89b92ef1e13e6a9",
            "df3f08b4dc0e4ca29b8976b483274c36",
            "0b0e936027e44a40ab8ecfbed3b2e303"
          ]
        },
        "id": "24ee9fe4-8e25-45a5-b56b-61c51b69bbb5",
        "outputId": "ada34872-abb5-4c90-bc0d-585c225293c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading concrete_data_week3.zip:   0%|          | 0/97863179 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8a243a49aff4d7e97c9d008e4928a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30036 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b2371ccfc5e4b8e9c311ae4c8c88552"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to '.'\n"
          ]
        }
      ],
      "source": [
        "## get the data\n",
        "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/concrete_data_week3.zip\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1926133-f936-42c7-8cec-7e5ebcbb20b9"
      },
      "source": [
        "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877483a0-cb76-4928-a36a-39785cf04808"
      },
      "source": [
        "## Define Global Constants\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b192844f-8ebf-485b-b97d-e525515fa5d2"
      },
      "source": [
        "Here, we will define constants that we will be using throughout the rest of the lab.\n",
        "\n",
        "1. We are obviously dealing with two classes, so *num_classes* is 2.\n",
        "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
        "3. We will training and validating the model using batches of 100 images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b5f7cace-b3c4-4e58-9c0d-5b52f3357713"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "\n",
        "image_resize = 224\n",
        "\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0183cdad-017f-41ea-ac37-d979b398ad16"
      },
      "source": [
        "<a id='item34'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cac7d34d-9a92-44de-8245-d22202b73b3a"
      },
      "source": [
        "## Construct ImageDataGenerator Instances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd27dd04-a55f-4c99-9259-0b2c3d296090"
      },
      "source": [
        "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "db7834eb-a1e4-4a4b-a075-29900939bdc4"
      },
      "outputs": [],
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b487ed3-ae96-4b96-8038-7e5cda19b36c"
      },
      "source": [
        "Next, we will use the *flow_from_directory* method to get the training images as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "595ecbe2-bfdc-4523-9acd-3706181796b8",
        "outputId": "16b0a118-ad01-4e64-8d67-fa2826bca24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160bbbd7-035b-4c35-b870-556433bcd577"
      },
      "source": [
        "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc0f0817-76c4-4467-a062-c0c302658371",
        "outputId": "fa9e5ea0-8c73-48ea-8cfd-f985e768f39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1e87236-bfd3-4ff8-942d-133ebd71d2d2"
      },
      "source": [
        "## Build, Compile and Fit Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f398574-9232-4051-8463-663fe90a2f47"
      },
      "source": [
        "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "324b72dc-2a07-48a6-a4e7-b91de8338dcd"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9ce8f4-3052-478f-92e0-412574a9ffba"
      },
      "source": [
        "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f75d767-8ca1-4cea-b11f-e8c73909ef35",
        "outputId": "d0faf7ce-e315-4377-d117-923fceb9e9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model.add(ResNet50(\n",
        "    include_top=False, # leave output layer out\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fa6e617-2400-470a-aad9-416bdc45f07b"
      },
      "source": [
        "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "517f94df-1874-457c-84e6-e1dba49f86e0"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd8b80d-795d-41cc-897f-d942bb8ceaa5"
      },
      "source": [
        "You can access the model's layers using the *layers* attribute of our model object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c3e20f7-ccd7-42aa-8a95-5bd0e5361899",
        "outputId": "0e533d90-811d-4658-e2f4-0f98dbfa148b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.engine.functional.Functional at 0x7f577ad37100>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7f5753b4d6c0>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ead62664-0389-4b64-a87b-31054cae45f1"
      },
      "source": [
        "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfb56e7f-9153-4ecb-a22f-34e4a82c3a1e"
      },
      "source": [
        "You can access the ResNet50 layers by running the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3adb56a8-130d-4e65-8f77-f015cf759afa",
        "outputId": "ac4bc945-6348-4806-f3ba-0c8bd718dcf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.engine.input_layer.InputLayer at 0x7f5753b4d8a0>,\n",
              " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7f5753b4de10>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753b4e2c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753b4ef50>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753b4fb80>,\n",
              " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7f57539202b0>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7f5753b4fe80>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753921b70>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753922770>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753923820>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539a40a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539a4520>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539a6680>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753b4e6e0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539a6b30>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753b4e650>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539a7250>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57539a7b20>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539c0820>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539c15a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539c1ed0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539c31f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539c17e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539c3250>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539c35e0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575393d750>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575393dab0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f575393e7d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575393fb50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575393e470>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575393e260>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539c98d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539ca0e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539c8520>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539caaa0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539c9e70>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539c9d50>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57539cbfa0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539edf00>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539a4400>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539229b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57539c8550>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539ee170>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539c04f0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575393fd30>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539cb760>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57539ed6c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539cbd30>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753a10a30>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57539ec9a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753a133d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753a11150>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753a13fa0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753a13640>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538e98d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538e8490>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538eb880>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538e92a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538e9ba0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57538ea320>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538fd810>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538fe6b0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538fe7d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538ff9a0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538feb60>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538fc3a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538ff8b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753912470>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753912800>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57539132b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753913850>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753874670>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753910f10>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753911ed0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538fc730>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57539efee0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f5753922c50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538fff10>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753a12170>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57538fed70>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538773a0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538899c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f5753889390>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575388b1c0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575388b670>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575388b310>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575388b430>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753877fd0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f5753899570>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538752d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538996f0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f575389a9b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575389b4c0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575389b1f0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575389b370>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538a96f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538a9ba0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538aa2c0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538abb50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538a8df0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538a9fc0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57538aba60>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538c2200>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538c11e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538c2bf0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538c1c00>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575381c7c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538c3ca0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538c2680>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538ab460>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538755d0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57538751e0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538c01f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538a9960>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575381de70>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575381f730>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575381fbe0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575381d9f0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575381fa90>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575386da20>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575386e1d0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f575386f010>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575386e3b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538c80a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538c8c40>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538ca6b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f57538cab60>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538c8ac0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f57538ca800>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acbc820>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acbc9a0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57538c84c0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acbe770>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acbf610>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acbf730>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acbf9d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acd4850>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acd4d60>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acd6da0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acd7250>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acd6620>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f577acd6fe0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acd6320>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575386fe20>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575381fa00>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f575386dcf0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f575381f790>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f575381c100>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acee020>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acbc6a0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577aced330>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f57538c9bd0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acef610>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f57538886d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577aceffd0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acfc7c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acefd30>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acfc970>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acfd210>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acffca0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577acffe50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577acfea40>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577acff9a0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f577acfe5c0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577ad1a230>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577ad19870>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577ad1a860>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577ad1af50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577ad1bf10>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577ad1b790>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577ad181c0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7f577ad35780>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f577ad365f0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7f577ad18fd0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7f577ad34e20>,\n",
              " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x7f577acef6d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.layers[0].layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcc55835-9b6a-4270-a922-ffc842a3b2f7"
      },
      "source": [
        "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ba503665-a9ca-456c-8a6a-072767030476"
      },
      "outputs": [],
      "source": [
        "model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb8c4bc5-43b0-41af-84b8-c3f44700a241"
      },
      "source": [
        "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25b95f54-b4f5-4ff5-b9f7-59bd877fc6f2",
        "outputId": "3ec89efb-0f01-4049-8eff-35194b450d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23591810 (90.00 MB)\n",
            "Trainable params: 4098 (16.01 KB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d174115c-5697-4575-a241-c2d6a67b25cf"
      },
      "source": [
        "Next we compile our model using the **adam** optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "e28af4b7-b584-47d9-a996-f6e1c880e2cf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eb49523-42bf-43ec-9932-122c88162abf"
      },
      "source": [
        "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb075ee5-15d6-4e6c-83e1-8bc4b9c9b927",
        "outputId": "6af85247-23b0-440f-b03c-ed10f78d9062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 50\n"
          ]
        }
      ],
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 2\n",
        "print(steps_per_epoch_training,steps_per_epoch_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e940f178-9402-4b49-a92d-5d49c5ce2d84"
      },
      "source": [
        "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRZm5kN56sv2"
      },
      "source": [
        "Note that `fit_generator` is deprecated since TensoFlow 2.1.0. Use `fit` instead!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b2a03e7-2a37-424c-ade0-fb9030bd4fa6",
        "outputId": "8724b7bf-c843-4634-9cc0-3546126a6807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "100/100 [==============================] - 3437s 34s/step - loss: 0.0559 - accuracy: 0.9806 - val_loss: 0.0134 - val_accuracy: 0.9962\n",
            "Epoch 2/2\n",
            "100/100 [==============================] - 3408s 34s/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0087 - val_accuracy: 0.9980\n"
          ]
        }
      ],
      "source": [
        "fit_history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ecefc5-ddd9-4a55-82e0-c2d85da6cfb6"
      },
      "source": [
        "Now that the model is trained, you are ready to start using it to classify images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "219a8c0f-7272-4344-86b1-b48a94bf8d06"
      },
      "source": [
        "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6886e4e0-12c1-4f92-9131-bb65e9448da1",
        "outputId": "85428197-ed37-4e2a-8d0b-0d0b74a8adbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('classifier_resnet_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5811996e-a9d9-4f55-b217-91b706c2b540"
      },
      "source": [
        "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8a243a49aff4d7e97c9d008e4928a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f46e0dc86b4db1adb3bb179598958f",
              "IPY_MODEL_0d8df91aaf1f4b16b54d1675f19ea2d1",
              "IPY_MODEL_000518ad4cff42b7a9ed30542d39c047"
            ],
            "layout": "IPY_MODEL_a550bcafa6f246878f2ef6f28e5f7b6d",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e0f46e0dc86b4db1adb3bb179598958f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8f478f75a44941f5b122db6ec0a42fa8",
            "placeholder": "​",
            "style": "IPY_MODEL_124e5f7c9ff8437dade44bb20913da03",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading concrete_data_week3.zip: 100%"
          }
        },
        "0d8df91aaf1f4b16b54d1675f19ea2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_88bfb5c1a4244fbfbd5f7c2e9b8ab9c0",
            "max": 97863179,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1b8a4f156f64317b13b07d26701af5e",
            "tabbable": null,
            "tooltip": null,
            "value": 97863179
          }
        },
        "000518ad4cff42b7a9ed30542d39c047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_de5ab5e8a035404c9f20901d054e56e2",
            "placeholder": "​",
            "style": "IPY_MODEL_d330de7491f04f5783e94bb079a3e14a",
            "tabbable": null,
            "tooltip": null,
            "value": " 97863179/97863179 [00:02&lt;00:00, 36133018.61it/s]"
          }
        },
        "a550bcafa6f246878f2ef6f28e5f7b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f478f75a44941f5b122db6ec0a42fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124e5f7c9ff8437dade44bb20913da03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "88bfb5c1a4244fbfbd5f7c2e9b8ab9c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b8a4f156f64317b13b07d26701af5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de5ab5e8a035404c9f20901d054e56e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d330de7491f04f5783e94bb079a3e14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4b2371ccfc5e4b8e9c311ae4c8c88552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a6355d7d47441778e873434265f9995",
              "IPY_MODEL_341d5f4d5820456d86df99e616409340",
              "IPY_MODEL_c22630f0a6c64c63b491f80c753830c2"
            ],
            "layout": "IPY_MODEL_7c8d039cc71241d69cbcd25f4e077a02",
            "tabbable": null,
            "tooltip": null
          }
        },
        "6a6355d7d47441778e873434265f9995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_46d3f53c5292428c81d1a05661b63593",
            "placeholder": "​",
            "style": "IPY_MODEL_f370084ae34a43e8b77724ceb902c580",
            "tabbable": null,
            "tooltip": null,
            "value": "Extracting concrete_data_week3.zip: 100%"
          }
        },
        "341d5f4d5820456d86df99e616409340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_02dd2b8688df49569dde27f64a96b89d",
            "max": 30036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d43da503d3b14bacb89b92ef1e13e6a9",
            "tabbable": null,
            "tooltip": null,
            "value": 30036
          }
        },
        "c22630f0a6c64c63b491f80c753830c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_df3f08b4dc0e4ca29b8976b483274c36",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0e936027e44a40ab8ecfbed3b2e303",
            "tabbable": null,
            "tooltip": null,
            "value": " 30036/30036 [00:06&lt;00:00, 3468.37it/s]"
          }
        },
        "7c8d039cc71241d69cbcd25f4e077a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46d3f53c5292428c81d1a05661b63593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f370084ae34a43e8b77724ceb902c580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "02dd2b8688df49569dde27f64a96b89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43da503d3b14bacb89b92ef1e13e6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df3f08b4dc0e4ca29b8976b483274c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0e936027e44a40ab8ecfbed3b2e303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}