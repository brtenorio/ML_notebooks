{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DhNE7DF8J5N"
      },
      "source": [
        "## Model persistence using SparkML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P7lLqMV8J5O"
      },
      "source": [
        "## __Table of Contents__\n",
        "\n",
        "<ol>\n",
        "  <li>\n",
        "    <a href=\"#Objectives\">Objectives\n",
        "    </a>\n",
        "  </li>\n",
        "  <li>\n",
        "    <a href=\"#Datasets\">Datasets\n",
        "    </a>\n",
        "  </li>\n",
        "  <li>\n",
        "    <a href=\"#Setup\">Setup\n",
        "    </a>\n",
        "    <ol>\n",
        "      <li>\n",
        "        <a href=\"#Installing-Required-Libraries\">Installing Required Libraries\n",
        "        </a>\n",
        "      </li>\n",
        "      <li>\n",
        "        <a href=\"#Importing-Required-Libraries\">Importing Required Libraries\n",
        "        </a>\n",
        "      </li>\n",
        "    </ol>\n",
        "  </li>\n",
        "  <li>\n",
        "    <a href=\"#Examples\">Examples\n",
        "    </a>\n",
        "    <ol>\n",
        "    <li>\n",
        "      <a href=\"#Task-1---Create-a-model\">Task 1 - Create a model\n",
        "      </a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#Task-2---Save-the-model\">Task 2 - Save the model\n",
        "      </a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#Task-3---Load-the-model\">Task 3 - Load the model\n",
        "      </a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#Task-4---Predict-using-the-loaded-model\">Task 4 - Predict using the loaded model\n",
        "      </a>\n",
        "    </li>\n",
        "    </ol>\n",
        "  </li>\n",
        "  <li>\n",
        "    <a href=\"#Exercises\">Exercises\n",
        "    </a>\n",
        "  </li>\n",
        "  <ol>\n",
        "    <li>\n",
        "      <a href=\"#Exercise-1---Create-a-model\">Exercise 1 - Create a model\n",
        "      </a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#Exercise-2---Save-the-model\">Exercise 2 - Save the model\n",
        "      </a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#Exercise-3---Load-the-model\">Exercise 3 - Load the model\n",
        "      </a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#Exercise-4---Predict-using-the-loaded-model\">Exercise 4 - Predict using the loaded model\n",
        "      </a>\n",
        "    </li>\n",
        "  </ol>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjM4O2Tr8J5O"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "After completing this lab you will be able to:\n",
        "\n",
        " - Save a trained model.\n",
        " - Load a saved model.\n",
        " - Make predictions using the loaded model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK3a2Z398J5P"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "In this lab you will be using dataset(s):\n",
        "\n",
        " - Modified version of car mileage dataset. Original dataset available at https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
        " - Modified version of diamonds dataset. Original dataset available at https://www.openml.org/search?type=data&sort=runs&id=42225&status=active\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyQ0fGZr8J5P"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QQeIXJR8J5P"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0hjEqjG8J5P",
        "outputId": "cf854f40-d25d-4aa5-d852-2808f6dac879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.1.2 -q\n",
        "!pip install findspark -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huQBr2Dt8J5Q"
      },
      "source": [
        "### Importing Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "id": "ezjbytxZ8J5Q"
      },
      "outputs": [],
      "source": [
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# FindSpark simplifies the process of using Apache Spark with Python\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#import functions/Classes for sparkml\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# import functions/Classes for metrics\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqrFuF5x8J5R"
      },
      "source": [
        "# Examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDxAXVGt8J5R"
      },
      "source": [
        "## Task 1 - Create a model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "xxBogulP8J5S"
      },
      "outputs": [],
      "source": [
        "#Create SparkSession\n",
        "#Ignore any warnings by SparkSession command\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Model Persistence\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMXK4Qr08J5S"
      },
      "source": [
        "Download the data file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1oftHLF8J5S",
        "outputId": "613825d9-d8b5-41c2-bcde-b5347bb6f546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-20 18:41:44--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13891 (14K) [text/csv]\n",
            "Saving to: ‘mpg.csv’\n",
            "\n",
            "mpg.csv             100%[===================>]  13.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-20 18:41:44 (302 MB/s) - ‘mpg.csv’ saved [13891/13891]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHKFOrWW8J5T"
      },
      "source": [
        "Load the dataset into the spark dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "id": "CvPis0c-8J5T"
      },
      "outputs": [],
      "source": [
        "# using the spark.read.csv function we load the data into a dataframe.\n",
        "# the header = True mentions that there is a header row in out csv file\n",
        "# the inferSchema = True, tells spark to automatically find out the data types of the columns.\n",
        "\n",
        "# Load mpg dataset\n",
        "mpg_data = spark.read.csv(\"mpg.csv\", header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYpu5ANp8J5T"
      },
      "source": [
        "Print the schema of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrAmbUcm8J5T",
        "outputId": "8c3d14d0-e5f9-4e9d-fbf0-478de59757bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- MPG: double (nullable = true)\n",
            " |-- Cylinders: integer (nullable = true)\n",
            " |-- Engine Disp: double (nullable = true)\n",
            " |-- Horsepower: integer (nullable = true)\n",
            " |-- Weight: integer (nullable = true)\n",
            " |-- Accelerate: double (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mpg_data.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTvNrifB8J5U"
      },
      "source": [
        "Show top 5 rows from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF5_ZcOS8J5U",
        "outputId": "fb7be213-cde2-4386-d83a-315de25029b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+-----------+----------+------+----------+----+--------+\n",
            "| MPG|Cylinders|Engine Disp|Horsepower|Weight|Accelerate|Year|  Origin|\n",
            "+----+---------+-----------+----------+------+----------+----+--------+\n",
            "|15.0|        8|      390.0|       190|  3850|       8.5|  70|American|\n",
            "|21.0|        6|      199.0|        90|  2648|      15.0|  70|American|\n",
            "|18.0|        6|      199.0|        97|  2774|      15.5|  70|American|\n",
            "|16.0|        8|      304.0|       150|  3433|      12.0|  70|American|\n",
            "|14.0|        8|      455.0|       225|  3086|      10.0|  70|American|\n",
            "+----+---------+-----------+----------+------+----------+----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mpg_data.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3U2h7Qw8J5U"
      },
      "source": [
        "We ask the VectorAssembler to group a bunch of inputCols as single column named \"features\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "id": "V9dW2WWj8J5U"
      },
      "outputs": [],
      "source": [
        "# Prepare feature vector\n",
        "assembler = VectorAssembler(inputCols=[\"Cylinders\", \"Engine Disp\", \"Horsepower\", \"Weight\", \"Accelerate\", \"Year\"], outputCol=\"features\")\n",
        "mpg_transformed_data = assembler.transform(mpg_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5ZQgSMz8J5U"
      },
      "source": [
        "Display the assembled \"features\" and the label column \"MPG\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nij0Bcv8J5U",
        "outputId": "2cf32f8e-06ff-4048-b9be-468625d9a678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|            features| MPG|\n",
            "+--------------------+----+\n",
            "|[8.0,390.0,190.0,...|15.0|\n",
            "|[6.0,199.0,90.0,2...|21.0|\n",
            "|[6.0,199.0,97.0,2...|18.0|\n",
            "|[8.0,304.0,150.0,...|16.0|\n",
            "|[8.0,455.0,225.0,...|14.0|\n",
            "|[8.0,350.0,165.0,...|15.0|\n",
            "|[8.0,307.0,130.0,...|18.0|\n",
            "|[8.0,454.0,220.0,...|14.0|\n",
            "|[8.0,400.0,150.0,...|15.0|\n",
            "|[8.0,307.0,200.0,...|10.0|\n",
            "|[8.0,383.0,170.0,...|15.0|\n",
            "|[8.0,318.0,210.0,...|11.0|\n",
            "|[8.0,360.0,215.0,...|10.0|\n",
            "|[8.0,429.0,198.0,...|15.0|\n",
            "|[6.0,200.0,85.0,2...|21.0|\n",
            "|[8.0,302.0,140.0,...|17.0|\n",
            "|[8.0,304.0,193.0,...| 9.0|\n",
            "|[8.0,340.0,160.0,...|14.0|\n",
            "|[6.0,198.0,95.0,2...|22.0|\n",
            "|[8.0,440.0,215.0,...|14.0|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mpg_transformed_data.select(\"features\",\"MPG\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os8ln20Y8J5V"
      },
      "source": [
        "We split the data set in the ratio of 70:30. 70% training data, 30% testing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "id": "7XVtv30D8J5V"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "(training_data, testing_data) = mpg_transformed_data.randomSplit([0.7, 0.3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwlxh7208J5V"
      },
      "source": [
        "Create a LR model and train the model using the pipeline on training data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "id": "yQZHfWVs8J5V"
      },
      "outputs": [],
      "source": [
        "# Train linear regression model\n",
        "# Ignore any warnings\n",
        "lr = LinearRegression(labelCol=\"MPG\", featuresCol=\"features\")\n",
        "pipeline = Pipeline(stages=[lr])\n",
        "model = pipeline.fit(training_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sogK0zC38J5V"
      },
      "source": [
        "## Task 2 - Save the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2LGWwcY8J5V"
      },
      "source": [
        "Create a folder where the model will to be saved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "TkvjzJw18J5W"
      },
      "outputs": [],
      "source": [
        "!mkdir model_storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "id": "7j60iWWR8J5W"
      },
      "outputs": [],
      "source": [
        "# Persist the model to the path \"./model_stoarage/\"\n",
        "\n",
        "model.write().overwrite().save(\"./model_storage/\")\n",
        "\n",
        "#The overwrite method is used to overwrite the model if it already exists,\n",
        "#and the save method is used to specify the path where the model should be saved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnqMNPzF8J5W"
      },
      "source": [
        "## Task 3 - Load the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "id": "C1pXUKHK8J5W"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "\n",
        "# Load persisted model\n",
        "loaded_model = PipelineModel.load(\"./model_storage/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le39L_EO8J5W"
      },
      "source": [
        "## Task 4 - Predict using the loaded model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [],
        "id": "nSvrb0278J5W"
      },
      "outputs": [],
      "source": [
        "# Make predictions on test data\n",
        "predictions = loaded_model.transform(testing_data)\n",
        "#In the above example, we use the load method of the PipelineModel object to load the persisted model from disk.\n",
        "#We can then use this loaded model to make predictions on new data using the transform method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39-k5k8q8J5X"
      },
      "source": [
        "Your model is now trained. We use the testing data to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "AGbvBtd98J5X"
      },
      "outputs": [],
      "source": [
        "# Make predictions on testing data\n",
        "predictions = model.transform(testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4A-pLfh8J5X",
        "outputId": "92e4ed1f-c1af-447c-89e0-2d8b5a70d3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|        prediction|\n",
            "+------------------+\n",
            "| 7.462967197566567|\n",
            "|  7.98727437499446|\n",
            "| 9.528458491359409|\n",
            "|10.553146326322494|\n",
            "| 17.17473453426735|\n",
            "+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.select(\"prediction\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOCrfJHi8J5X"
      },
      "source": [
        "Stop Spark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gPkFnjuR8J5X"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4lgbXzA8J5X"
      },
      "source": [
        "# Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCtgUskr8J5Y"
      },
      "source": [
        "### Exercise 1 - Create a model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh5G5XKo8J5Y"
      },
      "source": [
        "Create a spark session with appname \"Model Persistence Exercise\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-ZWidBVK8J5Y"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"Model Persistence Exercise\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klDib1Ds8J5Y"
      },
      "source": [
        "Download the data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yC5ECGR8J5Y",
        "outputId": "371199c5-a192-4340-a1c1-66c58067c39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-20 18:45:08--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diamonds.csv\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3192561 (3.0M) [text/csv]\n",
            "Saving to: ‘diamonds.csv’\n",
            "\n",
            "diamonds.csv        100%[===================>]   3.04M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-06-20 18:45:09 (128 MB/s) - ‘diamonds.csv’ saved [3192561/3192561]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/diamonds.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyuGFINg8J5Z"
      },
      "source": [
        "Load the dataset into a spark dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Dfk84STM8J5Z"
      },
      "outputs": [],
      "source": [
        "diamond_data = spark.read.csv(\"diamonds.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGqJv72Y8J5Z"
      },
      "source": [
        "Display sample data from dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d02T2eQK8J5Z",
        "outputId": "d957a4aa-34d2-4001-f875-fe5ec3946932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
            "|  s|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
            "+---+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
            "|  1| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
            "|  2| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
            "|  3| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
            "|  4| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
            "|  5| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
            "+---+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "diamond_data.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpeC6upz8J5Z"
      },
      "source": [
        "Assemble the columns columns carat,depth and table into a single column named \"features\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h-52YH2v8J5Z"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=[\"carat\", \"depth\", \"table\"], outputCol=\"features\")\n",
        "diamond_transformed_data = assembler.transform(diamond_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gOI7aMe8J5Z"
      },
      "source": [
        "Print the vectorized features and label columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCcZ_QUz8J5Z",
        "outputId": "924bd11c-d582-4a86-bdca-ab4db63dca0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|        features|price|\n",
            "+----------------+-----+\n",
            "|[0.23,61.5,55.0]|  326|\n",
            "|[0.21,59.8,61.0]|  326|\n",
            "|[0.23,56.9,65.0]|  327|\n",
            "|[0.29,62.4,58.0]|  334|\n",
            "|[0.31,63.3,58.0]|  335|\n",
            "+----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "diamond_transformed_data.select(\"features\",\"price\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yooe7Mys8J5Z"
      },
      "source": [
        "Split the dataset into training and testing sets in the ratio of 70:30.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2rcmoVDL8J5Z"
      },
      "outputs": [],
      "source": [
        "(training_data, testing_data) =  diamond_transformed_data.randomSplit([0.7, 0.3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yOVBQlF8J5a"
      },
      "source": [
        "Create a LR model and train the model using the pipeline on training data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KOFojMMm8J5a"
      },
      "outputs": [],
      "source": [
        "# Train linear regression model\n",
        "\n",
        "lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
        "pipeline = Pipeline(stages=[lr])\n",
        "model = pipeline.fit(training_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKMoNEHS8J5a"
      },
      "source": [
        "### Exercise 2 - Save the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEQy3Fhp8J5a"
      },
      "source": [
        "Create a folder \"diamond_model\". This is where the model will to be saved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Qh-NlLDu8J5a"
      },
      "outputs": [],
      "source": [
        "!mkdir diamond_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb0ATrh88J5a"
      },
      "source": [
        "Persist the model to the folder \"diamond_model\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3HC_P1Gv8J5a"
      },
      "outputs": [],
      "source": [
        "model.write().overwrite().save(\"./diamond_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scx-VjiW8J5b"
      },
      "source": [
        "### Exercise 3 - Load the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "821fp5Fu8J5b"
      },
      "source": [
        "Load the model from the folder \"diamond_model\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fugASw5B8J5b"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "\n",
        "# Load persisted model\n",
        "loaded_model = PipelineModel.load(\"./diamond_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmr5i9bC8J5b"
      },
      "source": [
        "### Exercise 4 - Predict using the loaded model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjUhfMyU8J5b"
      },
      "source": [
        "Make predictions on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "g-MhCWhO8J5c"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = loaded_model.transform(testing_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oDhoosQ8J5c",
        "outputId": "a10b7c79-1c4f-480b-dbd5-47a9a1970367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|        prediction|\n",
            "+------------------+\n",
            "|-744.0853604256281|\n",
            "|-553.4937151464674|\n",
            "|-63.97190568174665|\n",
            "|-65.48521394112322|\n",
            "|-983.1978916379358|\n",
            "+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.select(\"prediction\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5BXieo28J5c"
      },
      "source": [
        "Stop Spark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WpuWMtRS8J5c"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}